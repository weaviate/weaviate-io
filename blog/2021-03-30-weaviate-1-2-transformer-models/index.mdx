---
title: Weaviate 1.2 release - transformer models
slug: weaviate-1-2-transformer-models
authors: [etienne]
date: 2021-03-30
tags: ['release']
image: ./img/hero.png
# canonical-url: https://medium.com/semi-technologies/weaviate-version-1-2-x-now-supports-transformer-models-4a12d858cce3
# canonical-name: Medium
description: "Weaviate v1.2 introduced support for transformers (DistilBERT, BERT, RoBERTa, Sentence-BERT, etc) to vectorize and semantically search through your data."
---
![Weaviate 1.2 release - transformer models](./img/hero.png)

In the v1.0 release of Weaviate ([docs](/developers/weaviate/) — [GitHub](https://github.com/weaviate/weaviate)) we introduced the concept of [modules](/developers/weaviate/concepts/modules). Weaviate modules are used to extend the vector database with vectorizers or functionality that can be used to query your dataset. With the release of Weaviate v1.2, we have introduced the use of transformers ([DistilBERT](https://arxiv.org/abs/1910.01108), [BERT](https://github.com/google-research/bert), [RoBERTa](https://arxiv.org/abs/1907.11692), Sentence-[BERT](https://arxiv.org/abs/1908.10084), etc) to vectorize and semantically search through your data.

<!-- truncate -->

### Weaviate v1.2 introduction video

<div className="youtube">
    <iframe src="//www.youtube.com/embed/S4lXPPZvGPQ" frameBorder="0" allowFullScreen></iframe>
</div>

## What are transformers?
A [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) (e.g., [BERT](https://en.wikipedia.org/wiki/BERT_(language_model))) is a deep learning model that is used for NLP tasks. Within Weaviate the transformer module can be used to vectorize and query your data.

## Getting started with out-of-the-box transformers in Weaviate
By selecting the text-module in the [Weaviate configuration tool](/developers/weaviate/installation/docker-compose#configurator), you can run Weaviate with transformers in one command. You can learn more about the Weaviate transformer module [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers).

![Weaviate configurator — selecting the Transformers module](./img/configurator-demo.gif)
*Weaviate configurator — selecting the Transformers module*

## Custom transformer models
You can also use custom transformer models that are compatible with Hugging Face's `AutoModel` and `AutoTokenzier`. Learn more about using custom models in Weaviate [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers).

## Q&A style questions on your own dataset answered in milliseconds
Weaviate now allows you to get to sub-50ms results by using transformers on your own data. You can learn more about Weaviate’s speed in combination with transformers in [this article](https://towardsdatascience.com/a-sub-50ms-neural-search-with-distilbert-and-weaviate-4857ae390154).


import WhatNext from '/_includes/what-next.mdx'

<WhatNext />
