Weaviate `1.26` is here!

Here are the release ‚≠êÔ∏è*highlights*‚≠êÔ∏è!

![Weaviate 1.26](./img/hero.png)

- [**Improved Range Queries**](#improved-range-queries)
- [**Async Replication**](#async-replication)
- [**Anthropic integration**](#anthropic-integration)
- [**Bulk enable API-based modules**](#bulk-enable-modules)
- [**Multi target vector**](#multi-target-vector)
- [**Tenant statuses changed**](#tenant-statuses-changed)
- [**Tenant offload to cloud storage**](#tenant-offload-to-cloud-storage)
- [**Async Python client**](#async-python-client)
- [**Scalar Quantization**](#scalar-quantization)
- [**Dashboards for async indexes**](#dashboards-for-async-indexes)
- [**Korean tokenizer**](#korean-tokenizer)
- [**Additional changes**](#additional-changes)

## Improved Range Queries

Cool stuff goes here

## Async Replication

Cool stuff goes here

## Anthropic integration

Anthropic generative AI integration is now available in Weaviate. This integration allows you to use the `Claude` family of models from Anthropic to perform generative search on your data. The integration includes support for the latest models, such as `Claude 3.5 Sonnet`.

This integration will be enabled by default on Weaviate Cloud [WCD](https://console.weaviate.cloud/) instances.

To enable the Anthropic integration on a local deployment, add `generative-anthropic` to the `ENABLE_MODULES` [environment variable](/developers/weaviate/config-refs/env-vars.md), or use the `ENABLE_API_BASED_MODULES` environment variable as described below.

## Bulk enable modules

The `ENABLE_API_BASED_MODULES` [environment variable](/developers/weaviate/config-refs/env-vars.md) adds the ability to enable all relevant modules for API-based [model provider integrations](/developers/weaviate/model-providers/index.md) with one setting.

This you no longer have to enable each module individually in the `ENABLE_MODULES` environment variable.

`ENABLE_API_BASED_MODULES` works additively with the `ENABLE_MODULES` environment variable. If you set `ENABLE_API_BASED_MODULES` to `true`, and `ENABLE_MODULES` to `text2vec-ollama,generative-ollama,backup-s3` for example, `text2vec-ollama`, `generative-ollama`, and `backup-s3` are enabled as well as all API-based modules are enabled.

Note this feature is experimental and may change in future releases. Also keep in mind that enabling multiple modules will disable the [`Explore`](/developers/weaviate/api/graphql/explore.md) feature.

## Multi target vector

Cool stuff goes here

## Tenant statuses changed

Tenant [activity statuses](/developers/weaviate/concepts/data.md#tenant-status) were added in Weaviate `1.21` to allow unused tenants to not occupy valuable memory. These tenants were marked as `COLD` tenants, in contrast to `HOT` tenants that are actively used.

These statues have been changed in Weaviate `1.26` to `ACTIVE` and `INACTIVE` to better reflect the tenant status. Their functionalities remain the same; `ACTIVE` tenants are active and loaded in memory with read/write operations available to them, while `INACTIVE` tenants are stored on disk and not available for read nor write.

This is in addition to the new, `OFFLOADED` status.

## Tenant offload to cloud storage

In addition to the option of putting tenants in `INACTIVE` status, Weaviate `1.26` introduces the ability to "offload" tenants to cloud storage. This allows you to store tenants on lower-cost cloud storage and load them back into memory when needed.

Such a tenant is marked as `OFFLOADED` and is not available for read nor write operations. This adds a new level of flexibility to Weaviate, allowing you to store tenants on disk or in cloud storage, depending on your needs. While the tenant is being offloaded or being loaded back into memory, it will have the status of `OFFLOADING` or `ONLOADING` respectively.

Currently this is supported for AWS S3, with more cloud storage providers to be added in future releases.

:::warning
TODO - add links to docs
:::

## Async Python client

The Weaviate Python client library adds a `WeaviateAsyncClient` object that supports asynchronous operations. This allows you to use the client in an asynchronous manner, which can be useful for highly concurrent applications such as web servers.

:::warning
TODO - add links to docs
:::

## Scalar Quantization

Cool stuff goes here

## Dashboards for async indexes

Cool stuff goes here

## Korean tokenizer

A new Korean tokenizer is available in Weaviate `1.26` (and `1.25.7`). This tokenizer is based on the `kagome` library and a `MeCab` dictionary. To enable the Korean tokenizer, set the `ENABLE_TOKENIZER_KAGOME_KR` [environment variable](/developers/weaviate/config-refs/env-vars.md) to `true`, and set `kagome_kr` as the [tokenization method](/developers/weaviate/config-refs/schema/index.md#kagome_kr-tokenization-method) for the relevant properties.

Note this feature is experimental and may change in future releases.

## Additional changes

- Starting in Helm chart version 17.0.1, constraints on module resources are commented out to improve performance. To constrain resources for specific modules, add the constraints in your `values.yaml` file.

- The HNSW `maxConnections` value is updated. Instead of 64 connections, the HNSW graph now defaults to 32 connections.

 The lower value works better with modern ANN datasets that have high dimensionality. Testing shows that the QPS/recall curves improve with lower `maxConnections` values. The best values are in the 16-32 range, depending on dataset size. To improve target recall, `ef` can be increased.

## Summary

Enjoy the new features and improvements in Weaviate `1.26`. This release is available as a docker image and is coming soon to Weaviate Cloud [WCD](https://console.weaviate.cloud/).

Thanks for reading, see you next time üëã!
