---
title: Weaviate 1.21 Release
slug: weaviate-1-21-release
authors: [jp, zain]
date: 2023-08-22
image: ./img/hero.png
tags: ['release', 'engineering']
description: "Weaviate 1.21 released with new operators, performance improvements, multi-tenancy improvements, and more!"

---
Weaviate `1.21` is here and available on [Weaviate Cloud Services](https://console.weaviate.cloud/)!

Here are the ‚≠êÔ∏è*highlights*‚≠êÔ∏è relating to this release:

![Weaviate 1.21](./img/hero.png)

<!-- truncate -->
1. [`ContainsAny` and `ContainsAll` operators added](#containsany-and-containsall-operators) ‚Äì Convenient, new operators to simplify complex queries.
1. [Multi-tenancy improvements](#multi-tenancy-improvements) ‚Äì Experimental tenant deactivation for efficiency + improved performance.
1. [New vectorizer modules](#new-modules)
    - `text2vec-gpt4all` provides fast transformer inference on CPUs; and
    - `multi2vec-bind` vectorizes multi-modal data from up to 7 modalities.
1. [Performance improvements](#performance-improvements) ‚Äì A suite of improvements to search, indexing and backup performance.
1. [Hybrid search algorithm refinement](#hybrid-search-algorithm-refinement) - Improved scoring stability for small limits in hybrid search.

For more details, keep scrolling ‚¨áÔ∏è!

## `ContainsAny` and `ContainsAll` operators

![New `ContainsAll` / `ContainsAny` filter operators](./img/contains-all-any.png)

You asked for it - and it‚Äôs here! `1.21` adds `ContainsAny` and `ContainsAll` operators to make your filters (syntactically) sweeter than ever.

You can use these to reduce complex chains of `And` or `Or` where filters to simple, digestible, queries that are easier on your eye and your brain.

These operators allow you to filter an array property, using a query array.

`ContainsAny` will find all objects whose property contains one or more (i.e. *any*) of the query values. In other words - a series of `Or` statements.

`ContainsAll`, on the other hand, will find all objects whose property contains every single one (i.e. *all*) of the query values. This can replace a series of `And` statements.

This is one of our most-requested features, and we are very excited for you to try it out.

<details>
  <summary>Example usage</summary>

Consider a dataset of people (class `Person`), where each `Person` object has a `name` and a `languages_spoken` property.

A `ContainsAny` like this will return all `Person` objects whose `languages_spoken` values contain any of the listed languages in the query.

```graphql
{
  Get {
    Person (
      where: {
        path: ["languages_spoken"],
        operator: ContainsAny,
        valueText: ["Chinese", "French", "English"]
      }
    )
    {
      languages_spoken
      name
    }
  }
}
```

A `ContainsAll` query on the other hand will return all `Person` objects whose `languages_spoken` values contain every single one of the listed languages in the query.

```graphql
{
  Get {
    Person (
      where: {
        path: ["languages_spoken"],
        operator: ContainsAny,
        valueText: ["Chinese", "French", "English"]
      }
    )
    {
      languages_spoken
      name
    }
  }
}
```

</details>

## Multi-tenancy improvements

### Deactivate / activate tenant shards (experimental)

![Activate / Deactivate tenants](./img/mt-inactive.png)

We introduced multi-tenancy (MT) with `1.20`, and we are thrilled by your response do far.

`1.21` adds an (experimental) feature to deactivate or activate individual tenants. This will allow you to scale even bigger with ease, because inactive tenants' data will not take up any space in memory.

This is possible because under the hood, each [tenant is a partition shard](https://www.weaviate.io/blog/multi-tenancy-vector-search#built-in-isolation-through-lightweight-shards), and tenant shards can now be deactivated while still retaining the data. Deactivated (`COLD`) shards do not consume memory or file descriptors, so this enables an unlimited number of non-active shards, limited only by disk space, while giving active (`HOT`) shards access to resources that they need.

Deactivating unused subsets of data will help to reduce cost and improve the overall performance. We are very excited for you to [try it out](/developers/weaviate/api/rest/schema#multi-tenancy).

> Read more:
> - [REST API: Schema: Multi-tenancy](/developers/weaviate/api/rest/schema#multi-tenancy)
> - [Concepts: Data: Multi-tenancy](/developers/weaviate/concepts/data#multi-tenancy)

:::note This is an experimental feature
Please use it with caution.
:::

### Improved cycle management for MT

With `1.21`, we've improved resource usage in a MT environment.

As you might imagine, enabling large-scale MT requires managing a large number of processes, unifying and centralizing the scheduling of background processes in each shard.

We've improved the way Weaviate manages these processes, leading to a more stable setup in a MT environment.

## New modules

### `text2vec-gpt4all` module

![New `text2vec-gpt4all` module](./img/text2vec-gpt4all.png)

This module allows you to perform local vectorization of text using the [gpt4all](https://docs.gpt4all.io/gpt4all_python_embedding.html) library.

A key benefit of this module is that it is optimized for CPU using [`ggml`](https://github.com/ggerganov/ggml), enabling fast inference with a transformer-architecture model even without a GPU.

If you are looking to perform local vectorization and don't have a GPU, this module could be a great option for you.

:::note Available for `x86-64` devices only.
Currently, the `gpt4all` library currently does not support ARM devices, such as Apple M-series.
:::

> Read more:
> - [Modules: text2vec-gpt4all](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-gpt4all)

### `multi2vec-bind` module

![New `multi2vec-bind` module](./img/multi2vec-bind.png)

Expand beyond a few modalities! The `multi2vec-bind` module is able to vectorize data containing up to 7 modalities:

- text
- images
- videos
- audio
- inertial measurement unit (IMU, i.e. accelerometer and gyroscope data)
- single channel depth images, and
- single channel thermal images.

Built with the [ImageBind](https://github.com/facebookresearch/ImageBind) model, this module can vectorize data containing any number of the listed modalities above.

We know you've just been dying to vectorize that data from your accelerometer and gyroscope, and now you can! üòâ

> Read more:
> - [Modules: multi2vec-bind](/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-bind)

## Performance improvements

![Performance improvements](./img/performance.png)

### Alternative virtual memory access (pread vs mmap)

There is now an option to use `pread` for memory management by setting it in the `PERSISTENCE_LSM_ACCESS` [environment variable](/developers/weaviate/config-refs/env-vars).

Weaviate has been using `mmap` to map a portion of disk space to virtual memory. While `mmap` is performant, it can lead to stalling situations under heavy load or memory pressure due to Weaviate not being aware that the memory is in fact virtual.

If this is an issue for you, you can use `pread` for memory management.

`pread` provides better responsiveness and avoids inducing downtime in a cluster. The tradeoff is that `pread` does not provide the same memory management benefits as `mmap`, and may not be as fast as memory access.

The current default will remain `mmap` - so if you want to change it, you must set the `PERSISTENCE_LSM_ACCESS` [environment variable](/developers/weaviate/config-refs/env-vars) to `pread`.

<details>
  <summary>Further technical details</summary>

<p>

With `mmap`, the operating system handles the disk access. If enough memory is available, it can cache the entire disk, resulting in fast access.

</p><br/>
<p>

However, under heavy load or memory pressure, the use of `mmap` can lead to scalability issues and slow down the system.

</p><br/>
<p>

On the other hand, the `pread` function performs regular disk I/O at a specific position.

</p><br/>
<p>

It is similar to `mmap` in that it reads a specified number of bytes from a specific byte position. But, the Go runtime is aware of the disk I/O operations performed with `pread`, while it is not with `mmap` (as it is handled by the OS). So, disk I/O operations are handled differently between these two functions.

</p><br/>
<p>

With `pread`, When a goroutine is waiting for disk I/O, the Go runtime parks it and works on other tasks in the meantime. This means that the goroutine is not blocked and does not cause performance issues.

</p>

</details>

> Read more:
> - [References: Configuration: Environment variables](/developers/weaviate/config-refs/env-vars)
> - Paper: ["Do you really want to use mmap in your DBMS?"](https://db.cs.cmu.edu/mmap-cidr2022/)

### ARM64 speedups

For those of you on ARM processors, you'll be happy to know that `simd` instructions are now used for faster distance calculations on ARM64 processors.

This optimization results in significant performance (up to ~40%!) improvements, especially for large data sets and high-dimensional embeddings.

You don't have to do anything to take advantage of this feature. Weaviate automatically detects the architecture and enables the optimization if it is supported.

:::note A similar feature is already available for `x86-64` processors
:::

> Read more:
> - [References: Distance metrics: Implementations](/developers/weaviate/config-refs/distances#distance-implementations-and-optimizations)

### Vector indexing improvements

The vector indexing (HNSW) algorithm has been updated to improve performance. These improvements are expected to reduce indexing time and make data writing quicker.

#### Delta encoding

This release changes how the HNSW graph connections are stored in memory.

Previously, the graph was stored as an array with all the edges. But from `1.21`, the graph is stored as a delta-encoded array, which is more efficient.

This change is expected to improve indexing time and make data writing quicker to the HNSW graph.

#### Reduce HNSW lock contention

This improvement reduces the potential for HNSW lock contention, improving performance.

Previously, a global lock existed whose primary goal was to ensure thread safety during the HNSW growth operation. From `1.21` onward, this has been replaced dedicated lock that solely protects against this particular situation.

Our internal testing showed improved performance by up to 20% in some cases.

### Backup improvements

Your backups will now be smaller, and will likely incur lower costs from cloud storage providers.

The new and improved backup process combines and compresses the required files to one backup file. Where there are a large number of files - such as with multi-tenancy users - this will be particularly beneficial.

Not only will it compress the data, it will reduce the number of file operations,improving efficiency and reducing cloud storage costs.

:::note `1.21` backups cannot be used in `c1.20` and below
Due to this change, backups from `1.21` cannot be used to restore in a `1.20` instance.
:::

## Hybrid search algorithm refinement

We hae introduced a small change with our new hybrid fusion scoring algorithm.

Where hybrid search is carried out with a small limit, a higher (internal) limit is used to determine the scoring, before returning the results with the original limit.

This addresses a potential issue where the scoring could be unstable with a small limit, as the scoring is based on a small number of results.

As a user, you don't need to do anything to take advantage of this change. It is automatically applied to all hybrid searches.

## Summary

That's it from us - we hope you enjoy the new features and improvements in Weaviate `1.21`. The new Weaviate releases are available on [WCS](https://console.weaviate.cloud/). So you can try it out yourself on a free sandbox, or by upgrading!

Thanks for reading, and see you next time üëã!

import WhatNext from '/_includes/what-next.mdx'

<WhatNext />

