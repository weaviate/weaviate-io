Weaviate `1.25` is here!

Here are the release ‚≠êÔ∏è*highlights*‚≠êÔ∏è!

![Weaviate 1.25](./img/hero.png)

- [**Dynamic Vector Index**](/blog/weaviate-1-25-release#dynamic-vector-index) An index configuration that allows Weaviate to dynamically switch from flat to HNSW as object count increases.
- [**Raft**](/blog/weaviate-1-25-release#raft) Improves schema management for faster updates and more reliable clusters. 
- [**New Modules**](/blog/weaviate-1-25-release#new-modules) Loads of new modules that will allow you to use open source locally running and hosted embedding and language models!
- [**Batch vectorization**](/blog/weaviate-1-25-release#batch-vectorization)
- [**Automatic tenant creation**](/blog/weaviate-1-25-release#automatic-tenant-creatio)
- [**Search improvements**](/blog/weaviate-1-25-release#search-improvements)

## Dynamic Vector Index

![dynamic_index](./img/dynamic.png)

Configuring Weaviate and not sure if you have enough objects to justify building a full HNSW index or to stick to a flat index? We‚Äôve got good news for you: In 1.25 we‚Äôre introducing the dynamic vector index!

Previously you‚Äôd have to decide at the outset if you wanted a flat or HNSW index. The flat index was ideal for use cases with a small object count where brute force nearest neighbors search was viable and would provide lower memory overhead and good latency. As the object count increased the flat index would become prohibitively slow and this is what the HNSW index would solve.

With 1.25 you can now configure Weaviate to use a dynamic index. This will initially create a flat index to be used and once the number of objects exceeds a certain threshold (by default 10,000 objects) it will dynamically switch you over to an HNSW index. 

Here is how you can configure Weaviate to use a dynamic index:

```json
{
	"vectorIndexType": "dynamic",
	"vectorIndexConfig": {
		"distance": "dot",
		"threshold": 10000,
		"hnsw" : {
			... standard HNSW configuration
		},
		"flat": {
		  ... standard Flat configuration
		}
}
```

This is a one-way dynamic switch that converts the flat index to HNSW. The index does not switch back to a flat index even if the object count drops below the threshold.

Above the threshold value, HNSW indexes are faster for queries, but they also have a larger memory footprint.

Dynamic indexes are particularly useful in a multi-tenant setup. The resource costs are high to build an HNSW index for every tenant. However, if a tenant collection grows large enough, the index dynamically switches to HNSW. The smaller tenants continue to use flat indexes.

## New Modules

### OctoAI Modules

With version 1.25 we‚Äôre announcing an integration with OctoAI which will make it even easier for users to access many open source embedding and language models such as Llama3-70b, Mixtral-8x22b and more. 

We are releasing two modules: text2vec-octoai and generative-octoai that integrate Weaviate and the OctoAI service. OctoAI provides hosted inference services for embedding models and large language models.

The current models supported include:

	"qwen1.5-32b-chat"
	"meta-llama-3-8b-instruct"
	"meta-llama-3-70b-instruct"
	"mixtral-8x22b-instruct"
	"nous-hermes-2-mixtral-8x7b-dpo"
	"mixtral-8x7b-instruct"
	"mixtral-8x22b-finetuned"
	"hermes-2-pro-mistral-7b"
	"mistral-7b-instruct"
	"codellama-7b-instruct"
	"codellama-13b-instruct"
	"codellama-34b-instruct"
	"llama-2-13b-chat"
	"llama-2-70b-chat"

To get started using Weaviate with OctoAI all you need is an OctoAI API key that you can get [from here](https://octo.ai/)! Read more about how you can use the `generative-octoai` module [here](/add/link/here) and the `text2vec-octoai` module [here](/add/link/here).

### Multimodal Google PaLM Module:

The multi2vec-palm module is an update to v1.24 that lets you use Google‚Äôs hosted embedding models to embed multimodal data.

Prior to the release of this module if users wanted to embed multimodal data they‚Äôd have to self-host the embedding model on their own compute but with multi2vec-palm building multimodal applications is easier than ever. 

Using Google‚Äôs [multimodal embedding model](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings) you can now embed text, images and videos all into the same vector space and perform cross-modal retrieval!

Learn more about how you can use the module [here](/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-palm).

## Batch vectorization

## Automatic tenant creation

## Search improvements

## Summary

Enjoy the new features and improvements in Weaviate `1.25`. This release is available as a docker image and on [WCS](https://console.weaviate.cloud/). Try it out in a free, WCS sandbox, or download a copy and try it out locally.

Thanks for reading, see you next time üëã!
