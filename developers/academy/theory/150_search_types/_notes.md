### Vector embeddings

Vector embeddings are numerical representations of objects in a high-dimensional space. These vectors are generated by a model trained to represent the objects in a way that captures their semantic meaning.

A vector embedding may look like:

```json
[0, 1, 0, 0, 1]
```

or like:

```json
[0.158, 0.011, 0.840, 0.577, 0.897, ..., 0.144]
```

A vector embedding may be typically between 300 and 2048 dimensions, although the exact number varies depending on the model. The longer the vector, the more information it can capture about the object. On the other hand, they require more resources to store, index and search.

Vector embeddings that are produced by the same model are said to be "compatible", or that they are "in the same vector space".

:::tip Analog: Vector embeddings as language
An intuitive way to think of vector embeddings is as a language. Just as two people must speak the same language to communicate, two vectors must be in the same vector space to be compared. If two vectors are not in the same vector space, their values are meaningless when compared, even if they are the same length.
:::

## Vector distance

Vector distance indicates how close, or far apart, two vectors are in high-dimensional space. This is a measure of the object's "semantic" similarity to the query, based on their vector embeddings.

In a simple example, consider colors "SkyBlue", "LightSteelBlue", and "DarkOrange". These colors can be represented as vectors in a 3D space, with the RGB values as the vector components.

| Color          | Vector (R,G,B)  |
|----------------|-----------------|
| SkyBlue        | (135, 206, 235) |
| LightSteelBlue | (176, 196, 222) |
| DarkOrange     | (255, 140, 0)   |

The vectors for "SkyBlue" and "LightSteelBlue" are much closer to each other than either is to "DarkOrange", reflecting their similarity as light blue colors versus an orange color.

If you search a vector database containing vectors for "SkyBlue" and "DarkOrange" with a query vector for "LightSteelBlue", the search would return "SkyBlue" as the closest match.

Vector search for far more complex objects, such as text, images, or audio, is based on the same principle. The vectors are generated by a model trained to represent the objects in a high-dimensional space, where the distance between vectors reflects the similarity between the objects.

### Distance and search quality

All compatible vectors are similar to some degree search will have some "top" search results, even if the query is not similar to any objects in the dataset.

If you search a vector database containing vectors for colors "Red", "Crimson" and "LightCoral" with a query vector for "SkyBlue", the search will still return a result (e.g. "Red"), even if it is not semantically similar to the query. The search is simply returning the closest match, even if it is not a good match in the absolute sense.

To ensure that the search results are meaningful, consider the following strategies:

- **Use a threshold**: Set a minimum similarity score for the results. This will exclude results that are not similar enough to the query.
- **Apply filters**: Use [filters](../filtering.md) to exclude results based on other criteria, such as metadata or properties.
