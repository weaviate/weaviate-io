---
title: Tokenization and searches
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import FilteredTextBlock from '@site/src/components/Documentation/FilteredTextBlock';
import PyCreateCollection from '!!raw-loader!./_snippets/310_create_collection.py';
import PyAddObjects from '!!raw-loader!./_snippets/315_add_objects.py';
import PySearches from '!!raw-loader!./_snippets/400_searches.py';

Now that you've learned about different tokenization methods, let's put them into practice. In this section, you'll see how tokenization impacts search results in Weaviate.

## <i class="fa-solid fa-square-chevron-right"></i> Preparation

For this section, we'll work with an actual Weaviate instance to see how different tokenization methods impact search results.

We are going to use a very small, custom dataset for demonstration purposes.

<FilteredTextBlock
  text={PyAddObjects}
  startMarker="# StringsToAdd"
  endMarker="# END StringsToAdd"
  language="py"
/>

You can use the following Python code to add this data to your Weaviate instance.

Note: Importing the data yourself is optional. You can also perform queries against a pre-populated demo Weaviate instance.

<details>
  <summary>Steps to create a collection</summary>

We will create a simple object collection, with each object containing multiple properties. Each properties will contain the same text, but with different tokenization methods applied.

<FilteredTextBlock
  text={PyCreateCollection}
  startMarker="# CreateDemoCollection"
  endMarker="# END CreateDemoCollection"
  language="py"
/>

Note that we do not add object vectors in this case, as we are only interested in the impact of tokenization on keyword search results.

</details>

<details>
  <summary>Steps to add objects</summary>

Now, we add objects to the collection, repeating text objects as properties.

<FilteredTextBlock
  text={PyAddObjects}
  startMarker="# AddObjects"
  endMarker="# END AddObjects"
  language="py"
/>

</details>


## <i class="fa-solid fa-square-chevron-right"></i> Impact on filtering

Now that we have added a set of objects to Weaviate, let's see how different tokenization methods impact search results.

Each filtered query will look something like this, wherein we filter the objects for a set of query strings.

We'll set up a reusable function to filter objects based on a set of query strings. Remember that a filter is binary: it either matches or it doesn't.

The function will return a list of matched objects, and print the matched objects for us to see.

<FilteredTextBlock
  text={PyQueries}
  startMarker="# FilterExampleBasic"
  endMarker="# END FilterExampleBasic"
  language="py"
/>

### <i class="fa-solid fa-code"></i> Examples

#### "**Clark:** "vs "**clark**" - messy text

Typical text is often messy, with punctuations, mixed cases and other irregularities. Take a look at this example, where we search for various combinations of substrings from the TV show title `"Lois & Clark: The New Adventures of Superman"`.

The table shows whether the query matched the title:

|               | `word` | `lowercase` | `whitespace` | `field` |
|---------------|--------|-------------|--------------|---------|
| `"clark"`       | ✅     | ❌         | ❌          | ❌     |
| `"Clark"`       | ✅     | ❌         | ❌          | ❌     |
| `"clark:" `     | ✅     | ✅         | ❌          | ❌     |
| `"Clark:" `     | ✅     | ✅         | ✅          | ❌     |
| `"lois clark"`  | ✅     | ❌         | ❌          | ❌     |
| `"clark lois"`  | ✅     | ❌         | ❌          | ❌     |

<details>
  <summary>Python query & output</summary>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# ClarkExample"
  endMarker="# END ClarkExample"
  language="py"
/>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# ClarkResults"
  endMarker="# END ClarkResults"
  language="text"
/>

</details>

Note how the `word` tokenization was the only that consistently returned the matching title, unless the colon (`:`) was included in the query. This is because the `word` tokenization method treats the colon as a separator.

Users may not be expected to include any punctuation in their queries, nor the exact capitalization. As a result, for a typical text search, the `word` tokenization method is a good starting point.

#### "**A mouse**" vs "**mouse**" - stop words

Here, we search for variants of the phrase "computer mouse", where some queries include additional words.

Now, take a look at the results.

**Matches for `"computer mouse"`**

|                              | `word`    | `lowercase` | `whitespace` | `field` |
|------------------------------|-----------|-------------|--------------|---------|
| `"computer mouse"`           | ✅        | ✅           | ✅           | ✅     |
| `"a computer mouse"`         | ✅        | ✅           | ✅           | ❌     |
| `"the computer mouse:" `     | ✅        | ✅           | ✅           | ❌     |
| `"blue computer mouse" `     | ❌        | ❌           | ❌           | ❌     |

**Matches for `"a computer mouse"`**

|                              | `word`    | `lowercase` | `whitespace` | `field` |
|------------------------------|-----------|-------------|--------------|---------|
| `"computer mouse"`           | ✅        | ✅           | ✅           | ❌     |
| `"a computer mouse"`         | ✅        | ✅           | ✅           | ✅     |
| `"the computer mouse:" `     | ✅        | ✅           | ✅           | ❌     |
| `"blue computer mouse" `     | ❌        | ❌           | ❌           | ❌     |

<details>
  <summary>Python query & output</summary>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# MouseExample"
  endMarker="# END MouseExample"
  language="py"
/>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# MouseResults"
  endMarker="# END MouseResults"
  language="text"
/>

</details>

The results indicate that adding the word "a" or "the" to the query does not impact the search results for all methods except `field`. This is because at every tokenization method, the word "a" or "the" is considered a stop word and is ignored.

With the `field` method, the difference is that stop word tokens like "a" or "the" are never produced. An input "a computer mouse" is tokenized to `["a computer mouse"]`, containing one token.

Adding another word, such as "blue", that is not a stop word, causes the query to not match any objects.

#### "**variable_name**" vs "**variable name**" - symbols


|                              | `word`    | `lowercase` | `whitespace` | `field` |
|------------------------------|-----------|-------------|--------------|---------|
| `"variable_name"`            | ✅        | ✅           | ✅           | ✅     |
| `"Variable_Name:" `          | ✅        | ✅           | ❌           | ❌     |
| `"Variable Name:" `          | ✅        | ❌           | ❌           | ❌     |
| `"a_variable_name"`          | ✅        | ❌           | ❌           | ❌     |
| `"the_variable_name"`        | ✅        | ❌           | ❌           | ❌     |
| `"variable_new_name" `       | ✅        | ❌           | ❌           | ❌     |

<details>
  <summary>Python query & output</summary>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# UnderscoreExample"
  endMarker="# END UnderscoreExample"
  language="py"
/>

<FilteredTextBlock
  text={PyQueries}
  startMarker="# UnderscoreResults"
  endMarker="# END UnderscoreResults"
  language="text"
/>

</details>


### <i class="fa-solid fa-chalkboard"></i> Discussions


## <i class="fa-solid fa-square-chevron-right"></i> Impact on search


### <i class="fa-solid fa-code"></i> Search


### <i class="fa-solid fa-chalkboard"></i> Discussions


## <i class="fa-solid fa-square-chevron-right"></i> Conclusion

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>
