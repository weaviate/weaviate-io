---
title: Compression
sidebar_position: 17
image: og/docs/compression.jpg
# tags: ['getting started', 'connect']
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This page discusses compression methods that you can use to lower system requirements and save on infrastructure costs.

Weaviate stores objects and vector representations of those objects (vectors). By default, Weaviate creates uncompressed [HNSW](/developers/weaviate/concepts/vector-index#hierarchical-navigable-small-world-hnsw-index) vector indexes. HNSW indexes are fast and have excellent recall, but they also use a lot of RAM memory. RAM is expensive, so the cost of providing more RAM can limit the size of the collection.

Instead of the default configuration, you can use compression or a different index type to change the way Weaviate stores and searches your data.

## Compression methods

These compression algorithms are available:

- [Product Quantization (PQ)](/developers/weaviate/configuration/compression/pq-compression)
- [Binary Quantization (BQ)](/developers/weaviate/configuration/compression/bq-compression)
- [Scalar Quantization (SQ)](/developers/weaviate/configuration/compression/sq-compression)

## Compression considerations

Compression works well for most use cases. The trade-offs to consider are [cost, recall, and speed](#cost-recall-and-speed). The [underlying index](#underlying-index) determines which algorithms you can use, some compression methods aren't available with some index types. The [vectorizer](#compression-tuned-models) is also a consideration. Model providers may tune their models specifically for BQ or other compression algorithms.

### Cost, recall and speed

All compression algorithms save money the same way. The algorithms modify the way the vector dimensions are to stored to reduce vector size. Reduced storage size means you need less RAM to hold the index. all compression models also use more disk space than uncompressed vectors. Weaviate stores the uncompressed vector and the compressed vector. However, since the cost of RAM is orders of magnitude higher than the cost of disk, the overall cost to host a compressed index is much lower than the cost to host an uncompressed index.

Recall measures how well an algorithm finds the true positive matches in a data set. To improve recall, Weaviate over-fetches a list of candidate, compressed vectors. Then, for each item on the candidate list, Weaviate searches the item's uncompressed vector for a match. This technique means you get the benefits of compression without losing the precision of an uncompressed vector search.

Since compressed vectors are significantly smaller than uncompressed vectors, it is much faster to search a compressed data set than an uncompressed one. There is a small time cost when Weaviate searches the uncompressed candidate vectors, but this is small compared to the cost of searching a large uncompressed data set.

Importing and compressing vectors takes slightly longer than just importing them, but this is a one time cost. In contrast, loading a compressed index is faster since there is less data to load.

### Underlying index

- PQ is only available with [Hierarchical Navigable Small World (HNSW)](/developers/weaviate/concepts/vector-index#hierarchical-navigable-small-world-hnsw-index) indexes.
- BQ is available with [Flat indexes](/developers/weaviate/config-refs/schema/vector-index#flat-indexes) and HNSW indexes.



### Compression tuned models


### PQ and BQ compared

PQ analyzes your data to create centroids that are used to define segments. After compression, each segment represents a section of the original vector. PQ offers several advantages. The segment size, the number of centroids, and the encoder are all configurable. If you use PQ, you can experiment with these settings to find the best balance for your data set.

BQ is not tunable. The BQ algorithm reduces the value of each vector dimension to a single bit. Most uncompressed vectors store individual dimension values as 32 bit floats. An vector with 1536 dimensions requires 1536 * 32 bits of storage. After applying BQ, the same vector requires 1536 bits of storage. When the vectors have high dimensionality, BQ vectors are unique enough to preserve nuances even after such high compression.


## Related pages

For more information on compression, see these pages.

### Documentation pages

[Product Quantization (PQ)](/developers/weaviate/configuration/bq-compression)
[Binary Quantization (BQ)](/developers/weaviate/configuration/pq-compression)
[Compression discussion](/developers/weaviate/concepts/vector-quantization)

### Blog posts
[PQ and memory reduction](/blog/pq-rescoring)
[BQ and memory reduction](/blog/binary-quantization)

## Questions and feedback

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>


## CUT AND PASTE
Raw vectors can be very large. Vector dimensions are typically stored as arrays of 32 bit numbers. Vectors are indexed and the index is loaded in RAM memory so you can search your data quickly. Unfortunately, RAM is expensive and RAM requirements increase quickly for high-dimension vectors. Weaviate provides compression methods that you can tune to balance cost and performance.
