---
title: Compression
sidebar_position: 17
image: og/docs/compression.jpg
# tags: ['getting started', 'connect']
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Use compression to lower system requirements and save on infrastructure costs.

## Overview

Weaviate stores objects and vector representations of those objects (vectors). Vectors can be very large. Vector dimensions are stored as 32 bit floats, a single vector with 1536 dimensions uses about 6 KB of storage.

Weaviate creates indexes to search the vector space for your collection. By default, the index is an uncompressed [Hierarchical Navigable Small World (HNSW)](/developers/weaviate/concepts/vector-index#hierarchical-navigable-small-world-hnsw-index) index. HNSW indexes are fast and have excellent recall, but they also use a lot of RAM memory.

In many cases, you can use compression or a different index type to change the way Weaviate stores and searches your data. Updating the defaults can result in significant cost savings and performance improvements.

This page discusses compression methods. For more on indexes, see [Vector indexing](/developers/weaviate/concepts/vector-index).

## Compression methods

These compression algorithms are available:

- [Product Quantization (PQ)](/developers/weaviate/configuration/compression/pq-compression) PQ reduces the size of the vector embedding in two ways. PQ creates segments to reduce the number of dimensions, and segments are stored as 8 bit integers instead of 32 bit floats. Compared to dimensions, there are fewer segments and each segment is much smaller than a single dimension.

  The PQ compression algorithm is [configurable](/developers/weaviate/config-refs/schema/vector-index#pq-configuration-parameters).
You control the number of segments, segment granularity, and the size of the training set.
- [Scalar Quantization (SQ)](/developers/weaviate/configuration/compression/sq-compression) SQ reduces the size of each vector dimension from 32 bits to 8 bits. SQ trains on your data to create custom buckets for each dimension. This training helps SQ to preserve data characteristics when it maps 32 bit dimensions into 8 bit buckets.
- [Binary Quantization (BQ)](/developers/weaviate/configuration/compression/bq-compression) BQ reduces the size of each vector dimension to a single bit. It works best for vectors with high dimensionality.

When you compress data, the quality of your results depends heavily on the characteristics of the uncompressed data. The embedding model also plays a role in result quality. Before moving to production, experiment with different compression settings and models to find the combination that works best with your data set.

## Compression considerations

Before choosing a compression method, consider the [underlying index](#underlying-index). The index type determines which algorithms you can use. Some compression methods aren't available with some index types.

The vectorizer that you use to create your object vectors may also limit your compression choices. For example, some embedding models are tuned specifically for BQ compression.

Performance and cost are also important considerations. See [Cost, recall, and speed](#cost-recall-and-speed) for details.

### Underlying index

This table shows which compression algorithm is available for each index type.

| Compression type | HNSW index | Flat index | Dynamic index |
| :- | :- | :- | :- |
| PQ | Yes | No | Yes |
| SQ | Yes | No | Yes |
| BQ | Yes | Yes | Yes |

The [dynamic index](/developers/weaviate/config-refs/schema/vector-index#dynamic-indexes) is new in v1.25. This type of index is a [flat index](/developers/weaviate/config-refs/schema/vector-index#flat-indexes) until a collection reaches a threshold size. When the collection grows larger than the threshold size, the default is 10,000 objects, the collection is automatically reindexed and converted to an HNSW index.

### Cost, recall and speed

Performance includes speed and recall. In real world systems, these factors have to be balanced against cost. As you develop familiarity with your application, you can tune Weaviate to match your project and budget requirements.

#### Cost

These compression algorithms all help to control costs the same way. They reduce the size of the vector indexes. Smaller indexes need fewer resources so you spend less money.

Compressed indexes use less RAM when they are loaded into memory, however they also use more disk space than uncompressed vectors. Weaviate stores the uncompressed vector and the compressed vector index. This means increased disk storage. However, since the cost of RAM is orders of magnitude higher than the cost of disk, the overall cost to use a compressed index is much lower than the cost of using an uncompressed index.

The cost savings are obvious with in-memory indexes such as HNSW. The greater the RAM reduction, the smaller the costs.

- Uncompressed data size is roughly 7x greater than PQ compressed data.
- Uncompressed data size is roughly 4x greater than SQ compressed data.
- Uncompressed data size is roughly 32x greater than BQ compressed data.

#### Recall

Recall measures how well an algorithm finds true positive matches in a data set.

A compressed vector has less information than the full, uncompressed vector. A vector that would match a search might be missed if key information is missing from the compressed vector. That lowers recall.

To improve recall in BQ and SQ, Weaviate over-fetches a list of candidate vectors during a search. Then, for each item on the candidate list, Weaviate searches the corresponding uncompressed vector for a match. This followup search is slower than an in-memory search, but since Weaviate only has to search a limited number of uncompressed vectors, it is still very fast. Most importantly, searching the uncompressed vectors greatly improves recall.

PQ has tunable search parameters that can increase the size of the candidate pool. The mechanism is different, but the effect is the same as over-fetching in SQ and BQ. You can configure your PQ searches to return a vector candidate pool that boosts recall to meet your application requirements.

The over-fetching technique, also call rescoring, means you get the benefits of compression without losing the precision of an uncompressed vector search.

#### Query speed

Compressed vectors are significantly smaller than uncompressed vectors. It is much faster to search a compressed data set than an uncompressed one. After Weaviate creates a candidate list, there is a small time cost to search the uncompressed candidate vectors. This cost is small compared to the cost of searching a large, uncompressed data set, and the improved recall justifies the time spent.

Each compression method has its own characteristics with regard to speed.

- PQ indexes have response rates approach the response rates of uncompressed indexes when recall reaches 97 percent and higher. At those levels of recall, the [speed profile](/blog/pq-rescoring#qps-vs-recall-experiments) for PQ compressed indexes matches the profile for uncompressed indexes.

- BQ uses fast, bitwise calculations. The flat index relies on brute-force search so it is calculation intensive. BQ's bitwise calculations are extremely efficient. Searches of BQ compressed data can be as much as [10 to 20 times as fast](/binary-quantization#-performance-improvements-with-bq) as similar searches of uncompressed data and with equivalent rates of recall. BQ is sensitive to the underlying data. If you use a flat index, evaluate BQ compression to verify the performance improvements with your data set.

- SQ significantly improves search speeds. SQ is new in v1.26. It is faster than PQ, perhaps 3 to 4 times as fast as searching uncompressed data. SQ has a higher dimensional resolution than BQ that helps recall. Look for an upcoming blog post that discusses the tradeoffs with SQ compression.

SQ and BQ both have optional vector caches. Use these configurable caches to load frequently used, uncompressed vectors into memory to improve overall search times.

#### Import speed

Importing and compressing vectors takes slightly longer than importing uncompressed vectors, but this is a one time cost. In contrast, loading a compressed index into memory is faster since there is less data to load.

Starting in v1.22, Weaviate has an optional, [asynchronous indexing](/developers/weaviate/config-refs/schema/vector-index#asynchronous-indexing) feature which effectively speeds up the import process. Consider enabling asynchronous indexing to improve imports.

### Activate compression

PQ and SQ both require training data. PQ has to define centroids for each segment. SQ has to determine the minimum and maximum values for the bucket boundaries. When you have imported a large enough training set, the algorithm will compress your data.

SQ has to be enabled when you create the collection.

If you have async indexing and [AutoPQ enabled](/developers/weaviate/configuration/compression/pq-compression#configure-autopq), PQ compression can be started anytime. If not, you should only enable PQ after you have imported enough objects to [train the algorithm](/developers/weaviate/configuration/compression/pq-compression#manually-configure-pq).

BQ doesn't require a training step, however it can only be enabled when you create your collection. BQ cannot be enabled after you start to add data to the collection.

## Recommendations

Most applications benefit from compression.

- The cost savings are significant. In [Weaviate Cloud](https://weaviate.io/pricing), for example, compressed collections can be more than 80% cheaper than uncompressed collections.
- If you have a small collection that uses a flat index, consider a BQ index. The BQ index is 32 times smaller and much, much faster than the uncompressed equivalent.
- If you have specialized needs and a very large data set, consider PQ compression. PQ compression is very configurable, but it requires more expertise to tune well than SQ or BQ.
- Most users with medium to large data sets should consider SQ compression. SQ compressed vectors are one quarter the size of uncompressed vectors. Searches with SQ are several times faster than searches with uncompressed vectors. Recall is similar to uncompressed data.

Finally, for collections that are small, but that are expected to grow, consider a dynamic index. Configure the collection to use BQ compression while the index is flat and SQ compression when the collection grow large enough to move from a flat index to an HNSW index.

## Related pages

For more information on compression, see these documentation pages and blog posts.

### Documentation pages

To
[Product Quantization (PQ)](/developers/weaviate/configuration/bq-compression)
[Binary Quantization (BQ)](/developers/weaviate/configuration/pq-compression)
[Compression discussion](/developers/weaviate/concepts/vector-quantization)

### Blog posts

[PQ and memory reduction](/blog/pq-rescoring)
[BQ and memory reduction](/blog/binary-quantization)
[PQ and HNSW explained](/blog/ann-algorithms-hnsw-pq)

### Pricing calculator

[Weaviate cloud pricing](https://weaviate.io/pricing)

## Questions and feedback

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>
