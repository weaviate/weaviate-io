---
title: Compression
sidebar_position: 17
image: og/docs/compression.jpg
# tags: ['getting started', 'connect']
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This page discusses compression methods that you can use to lower system requirements and save on infrastructure costs.

Weaviate stores objects and vector representations of those objects (vectors). By default, Weaviate creates uncompressed [Hierarchical Navigable Small World (HNSW)](/developers/weaviate/concepts/vector-index#hierarchical-navigable-small-world-hnsw-index) vector indexes. HNSW indexes are fast and have excellent recall, but they also use a lot of RAM memory.

In many cases, you can use compression or a different index type to change the way Weaviate stores and searches your data.

For more on indexes, see [Vector indexing](/developers/weaviate/concepts/vector-index).

## Compression methods

These compression algorithms are available:

- [Product Quantization (PQ)](/developers/weaviate/configuration/compression/pq-compression) PQ uses segments to reduce the size of the vector embedding. Each segment represents a section of the original embedding. PQ uses training data to determine the segment characteristics.
- [Binary Quantization (BQ)](/developers/weaviate/configuration/compression/bq-compression) BQ reduces the size of each vector dimension to a single bit. It works best for vectors with high dimensionality.
- [Scalar Quantization (SQ)](/developers/weaviate/configuration/compression/sq-compression) SQ uses buckets to reduce the size of the vector representation. SQ uses training data to set the bucket size, then SQ maps each 32 bit dimension into an 8 bit bucket.

## Compression considerations

Before choosing a compression method, consider the [underlying index](#underlying-index). The index type determines which algorithms you can use. Some compression methods aren't available with some index types.

The [vectorizer](#compression-tuned-models) that you use to create your object vectors may limit your compression choices. For example, some embedding models are tuned specifically for BQ compression.

[Performance and cost](#cost-recall-and-speed) are also important considerations.

### Underlying index

This table shows which compression algorithm is available for each index type.

| Compression type | HNSW index | Flat index | Dynamic index |
| :- | :- | :- | :- |
| PQ | Yes | No | Yes |
| SQ | Yes | No | Yes |
| BQ | Yes | Yes | Yes |

- PQ is only available with HNSW indexes.
- SQ is only available with HNSW indexes
- BQ is available with [Flat indexes](/developers/weaviate/config-refs/schema/vector-index#flat-indexes) and HNSW indexes.

The [dynamic index](/developers/weaviate/config-refs/schema/vector-index#dynamic-indexes) is new in v1.25. This type of index is a flat index
until a collection reaches a threshold size. When the collection grows larger than the threshold size, the default is 10,000 objects, the collection is automatically reindexed and converted to an HNSW index.

### Cost, recall and speed

Performance includes speed and recall. In real world systems, these factors have to be balanced against cost. As you develop familiarity with your application, you can tune Weaviate to match your project and budget requirements.

#### Cost

All compression algorithms control costs the same way. They reduce the size of the vector indexes. Smaller indexes that run in RAM need fewer resources so you spend less money.

Compressed indexes use more disk space than uncompressed vectors. Weaviate stores the uncompressed vector and the compressed vector index. However, since the cost of RAM is orders of magnitude higher than the cost of disk, the overall cost to use a compressed index is much lower than the cost of using an uncompressed index.

The cost savings are obvious with in memory indexes such as HNSW. The greater the RAM reduction, the smaller the costs.

- Uncompressed data is roughly 7x greater than PQ compressed data.
- Uncompressed data is roughly 4x greater than SQ compressed data.
- Uncompressed data is roughly 32x greater than BQ compressed data.

For additional details, refer to the [blog posts](#blog-posts).

#### Recall

Recall measures how well an algorithm finds the true positive matches in a data set. A compressed vector has less information than the full, uncompressed vector. A vector that would match a search might be missed if key information is missing from the compressed vector. That lowers recall.

To improve recall, Weaviate over-fetches a list of candidate vectors during a search. Then, for each item on the candidate list, Weaviate searches the corresponding uncompressed vector for a match. This search is slower than an in-memory search, but since Weaviate only has to search a limited number of uncompressed vectors, it is very fast and it greatly improves recall.

The over-fetching technique means you get the benefits of compression without losing the precision of an uncompressed vector search.

#### Speed

Since compressed vectors are significantly smaller than uncompressed vectors, it is much faster to search a compressed data set than an uncompressed one. There is a small time cost when Weaviate searches the uncompressed candidate vectors, but this is small compared to the cost of searching a large uncompressed data set.

Importing and compressing vectors takes slightly longer than just importing them, but this is a one time cost. In contrast, loading a compressed index is faster since there is less data to load.




### Compression tuned models


### Implementation

## Related pages

For more information on compression, see these pages.

## PQ, SQ, and BQ compared

PQ analyzes your data to create centroids that are used to define segments. After compression, each segment represents a section of the original vector. PQ offers several advantages. The segment size, the number of centroids, and the encoder are all configurable. If you use PQ, you can experiment with these settings to find the best balance for your data set.

BQ is not tunable. The BQ algorithm reduces the value of each vector dimension to a single bit. Most uncompressed vectors store individual dimension values as 32 bit floats. An vector with 1536 dimensions requires 1536 * 32 bits of storage. After applying BQ, the same vector requires 1536 bits of storage. When the vectors have high dimensionality, BQ vectors are unique enough to preserve nuances even after such high compression.

### Documentation pages

[Product Quantization (PQ)](/developers/weaviate/configuration/bq-compression)
[Binary Quantization (BQ)](/developers/weaviate/configuration/pq-compression)
[Compression discussion](/developers/weaviate/concepts/vector-quantization)

### Blog posts
[PQ and memory reduction](/blog/pq-rescoring)
[BQ and memory reduction](/blog/binary-quantization)

## Questions and feedback

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>


## CUT AND PASTE
Raw vectors can be very large. Vector dimensions are typically stored as arrays of 32 bit numbers. Vectors are indexed and the index is loaded in RAM memory so you can search your data quickly. Unfortunately, RAM is expensive and RAM requirements increase quickly for high-dimension vectors. Weaviate provides compression methods that you can tune to balance cost and performance.
