---
title: Multi-vector encodings
sidebar_position: 30
image: og/docs/configuration.jpg
# tags: ['configuration', 'compression']
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import FilteredTextBlock from '@site/src/components/Documentation/FilteredTextBlock';
import PyCode from '!!raw-loader!/\_includes/code/howto/manage-data.collections.py';

Multi-vector embeddings represent a single data object, like a document or image, using a set of multiple vectors rather than a single vector. This approach allows for a more granular capture of semantic information, as each vector can represent different parts of the object. However, this leads to a significant increase in memory consumption, as multiple vectors are stored for each item.

Compression techniques become especially crucial for multi-vector systems to manage storage costs and improve query latency. **Encodings** transform the entire set of multi-vectors into a new, more compact single vector representation while aiming to preserve semantic relationships.

## MUVERA encoding

**MUVERA**, which stands for _Multi-Vector Retrieval via Fixed Dimensional Encodings_, tackles the higher memory usage and slower processing times of multi-vector embeddings by encoding them into single, fixed-dimensional vectors. This leads to reduced memory usage compared to traditional multi-vector approaches.

<!-- TODO[g-despot]: Add link to blog post: Read more about it in this blog post. -->

<Tabs groupId="languages">
  <TabItem value="py" label="Python Client v4">
    <FilteredTextBlock
      text={PyCode}
      startMarker="# START MultiValueVectorMuvera"
      endMarker="# END MultiValueVectorMuvera"
      language="py"
    />
  </TabItem>
  <TabItem value="js" label="JS/TS Client v3">

```typescript
// TS/JS support coming soon
```

  </TabItem>
  <TabItem value="java" label="Java">

```java
// Java support coming soon
```

 </TabItem>
  <TabItem value="go" label="Go">

```go
// Go support coming soon
```

</TabItem>
</Tabs>

The final dimensionality of the MUVERA encoded vector will be
`repetition * 2^ksim * dprojections`. Carefully tuning these parameters
is crucial to balance memory usage and retrieval accuracy.

These parameters can be used to fine-tune MUVERA:

- **`ksim`** (`int`):
  The number of Gaussian vectors sampled for the SimHash partitioning function.
  This parameter determines the number of bits in the hash, and consequently,
  the number of buckets created in the space partitioning step. The total
  number of buckets will be $2^{ksim}$. A higher value of `ksim` leads to a
  finer-grained partitioning of the embedding space, potentially improving
  the accuracy of the approximation but also increasing the dimensionality
  of the intermediate encoded vectors.

- **`dprojections`** (`int`):
  The dimensionality of the sub-vectors after the random linear projection
  in the dimensionality reduction step. After partitioning the multi-vector
  embedding into buckets, each bucket's aggregated vector is projected down
  to `dprojections` dimensions using a random matrix. A smaller value of
  `dprojections` helps in reducing the overall dimensionality of the final
  fixed-dimensional encoding, leading to lower memory consumption but potentially
  at the cost of some information loss and retrieval accuracy.

- **`repetition`** (`int`):
  The number of times the space partitioning and dimensionality reduction
  steps are repeated. This repetition allows for capturing different perspectives
  of the multi-vector embedding and can improve the robustness and accuracy
  of the final fixed-dimensional encoding. The resulting single vectors from
  each repetition are concatenated. A higher number of repetitions increases
  the dimensionality of the final encoding but can lead to better approximation
  of the original multi-vector similarity.

:::note Quantization
Quantization is also available as a compression technique for multi-vector embeddings. It reduces the memory footprint of individual vectors by approximating their values with less precision. Just like with single vectors, multi-vectors support [PQ](./pq-compression.md), [BQ](./bq-compression.md) and [SQ](./sq-compression.md) quantization.
:::

## Further resources

- [How-to: Manage collections](../../manage-data/collections.mdx#define-multi-vector-embeddings-eg-colbert-colpali)
- [Concepts: Vector quantization](/developers/weaviate/concepts/vector-quantization.md)

## Questions and feedback

import DocsFeedback from '/\_includes/docs-feedback.mdx';

<DocsFeedback/>
