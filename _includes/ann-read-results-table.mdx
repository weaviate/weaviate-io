<details>
  <summary>How to read the results table</summary>
<ul>
  <li>
    <strong>Choose the desired limit using the tab selector above the table.</strong> <br/>
    The limit describes how many objects are returned for a query.
    Different use cases require different levels of QPS
    and returned objects per query. <br/>
    For example, at 100 QPS and <code>limit 100</code> (100 objects per query) 10,000 objects will be returned in total. 
    At 1,000 QPS and <code>limit 10</code> (10 objects per query), you
    will also receive 10,000 objects in total as each request contains fewer
    objects, but you can send more requests in the same timespan. <br/>
    Pick the value that matches your desired limit in production most closely.
  </li>
  <li>
    <strong>Pick the desired configuration</strong> <br/>
    The first three columns represent the different input parameters to configure the HNSW index. These inputs lead to the results shown in columns four through six.
  </li>
  <li>
    <strong>Recall/Throughput Trade-Off at a glance</strong> <br/>
    The highlighted columns (Recall, QPS) reflect the Recall/QPS trade-off.
    Generally, as the Recall improves, the throughput drops. Pick the row
    that represents a combination that satisfies your requirements. Since
    the benchmark is multi-threaded and running on a 30-core machine, the
    QPS/vCore columns shows the throughput per single CPU core. You can use
    this column to extrapolate what the throughput would be like on a
    machine of different size. See also this section below
    <a href="#what-happens-if-i-run-with-fewer-or-more-cpu-cores-than-on-the-example-test-machine">outlining what changes to expect when running on different hardware.</a>
  </li>
  <li>
    <strong>Latencies</strong> <br/>
    Besides the overall throughput, columns seven and eight show the
    latencies for individual requests. The Mean Latency columns shows the
    mean over all 10,000 test queries. The p99 Latency shows the maximum
    latency for the 99th-percentile of requests. In other words, 9,900 out
    of 10,000 queries will have a latency equal to or lower than the
    specified number. The <a href="#what-is-a-p99-latency">difference
      between mean and p99</a> helps you get an impression how stable the
    request times are in a highly concurrent setup.
  </li>
  <li>
    <strong>Import times</strong> <br/>
    Changing the configuration parameters can also have an effect on the
    time it takes to import the dataset. This is shown in the last column.
  </li>
</ul>

</details>