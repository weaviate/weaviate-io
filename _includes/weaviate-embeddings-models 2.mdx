### `Snowflake/snowflake-arctic-embed-l-v2.0` (default) {#snowflake-arctic-embed-l-v2.0}

- A 568M parameter, 1024-dimensional model for multilingual enterprise retrieval tasks.
- Trained with Matryoshka Representation Learning to allow vector truncation with minimal loss.
- Quantization-friendly: Using scalar quantization and 256 dimensions provides 99% of unquantized, full-precision performance.
- Read more at the [Snowflake blog](https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0), and the Hugging Face [model card](https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0)
- Allowable `dimensions`: 1024 (default), 256

---

### `Snowflake/snowflake-arctic-embed-m-v1.5` {#snowflake-arctic-embed-m-v1.5}

- A 109M parameter, 768-dimensional model for enterprise retrieval tasks in English.
- Trained with Matryoshka Representation Learning to allow vector truncation with minimal loss.
- Quantization-friendly: Using scalar quantization and 256 dimensions provides 99% of unquantized, full-precision performance.
- Read more at the [Snowflake blog](https://www.snowflake.com/engineering-blog/arctic-embed-m-v1-5-enterprise-retrieval/), and the Hugging Face [model card](https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5)
- Allowable `dimensions`: 768 (default), 256

:::info Input truncation
Currently, input exceeding the model's context windows is truncated from the right (i.e. the end of the input).
:::
